\documentclass[]{article}

% Used packages
\usepackage{multicol} % allows to use multiple column alignment
\usepackage{graphicx} % allows to use graphics
\usepackage{caption} %allows more extensive caption formating
\usepackage{appendix} %allows to add appendix
\usepackage{adjustbox} %allows to make pictures wider than text marging

%opening
\title{Extracting objective facts \\ from subjective and noisy sources}
\author{Kirill Tumanov \& Panagiotis Chatzichristodoulou}

\begin{document}

\maketitle

\begin{abstract}
\noindent
In a world where media coverage is enormous and one can easily be over-flooded with opinionated and subjective information the need for automatic fact extraction increases by the day. A highly controversial crisis in Ukraine was chosen as a research subject, since it created strong opinions and that facts were masked behind subjective voices. The main focus of this work was to implement a text processing framework that receives data from differently aligned sources and outputs the underlying facts of the data. In addition, this work also aimed to show the limitations and possible improvements of the proposed framework along with the visualization examples.
\end{abstract}

%
\section{Introduction}
%
Modern news agencies cover the ongoing events with a great deal of subjectivity and dispute. This may be related to the general complexity of the causal relations in each situation nowadays, but also to the desire to put the events in a different light so that their story sells best. Whichever the reason is it is becoming more and more demanding for the reader to grasp what actually is going on. Especially when it comes to the analysis of the several information sources.

Recently it became very popular to discover and evaluate polarity of the opinions on the web by emotional and sentiment mining. This analysis is useful specifically for uncovering of the (mostly author's) attitude towards the situation. However, it does not provide any insight in what exactly was criticized or admired. In other words, it does not provide the context for the overall result, it just presents the attitude.

When a more pragmatic and detailed analysis is needed, fact extraction comes into play. An underlying basis of the present work is the belief that the proper information presentation is free of the emotional flavor, and that each story is comprised of a set of interrelated facts and events. When it comes to understanding the situation, only facts matter.

An example of both subjective and noisy information sources would be having the articles with different values of the magnitude of an earthquake. In this case as soon as the earthquake occurs, the first articles have different magnitude of the earthquake but after some time, when the scientists agree on the number they all converge to it. An example of only the subjective data would be articles referring to casualties of war. These data would have an extra challenge being correctly mined as in such cases each side claims a different number of victims. Furthermore, those numbers do not change over time due to the fact that they are solely subjective and not noisy.

The purpose of this work was to extract the set of facts from a list of sources to be able to track the situation regardless of the way it is presented. This means that objective facts from articles with subjective and noisy data are mined for the extraction.
%
\section{Information Retrieval}
%
%
\subsection{Introduction to the Mined Topic}
%
The hottest topic of the days of the work was a political crisis in Ukraine. Since a lot of the articles were written on the topic every day it was selected for investigation. It was observed that the Russian and the West policies were polar and that was another reason for mining of those sources.

The eight following news agencies from Russia, the West, China and Middle East were used as sources of the info on the topic:
\begin{multicols}{2}
	\begin{itemize}
		\itemsep 0em
		\item Russia Today 
		\item CNN
		\item Washington Post
		\item Reuters
		\item RIA Novosti
		\item ITAR-TASS
		\item Al-Jazeera
		\item Xinhua
	\end{itemize}
\end{multicols}
%
\subsection{Data Crawling and Parsing}
%
It was decided to retrieve articles from the agencies' RSS feeds. For that purpose at first a custom built parser was implemented in Perl~\cite{perl}. The parser basic structure consists of: 
\begin{enumerate}
	\item The crawler (is installed on a crawl job to query the given list of feeds for all new articles)
	\item The source parser (filters only the articles containing one of the keywords in the manually created dictionary (which in this work contained 35 words))
	\item The HTML data parser (removes the HTML tags from the articles)
	\item The meta-information handler (saves the information about the time article was published, its title and the publisher agency)
\end{enumerate}
However, this manual approach was soon discarded mainly due to the poor quality of the HTML tag removal, which left a lot of garbage data from the web pages (e.g. banner titles, links, etc.). 

Since then, the parser built in KNIME~\cite{knime} was used for the same purpose. The major difference in the structure was in an addition of a scoring block which evaluated article ``relativeness" to the topic. This block was built based on the same dictionary as discussed. The minimum acceptable threshold of matching words was set to two. Other processing steps mainly were the same, but the article text retrieval quality was much better and disc space was almost unused since information was kept in the form of links as long as it was possible. 

For the KNIME-built parser notable is the inability to extract the meta information about the articles. Therefore, the workaround for that problem had to be implemented. As a result of an information retrieval stage each article with its full corresponding meta-information was reconstructed in the form of a table entry. In total, the data table used consisted of 1891 entries.
%
\section{Preprocessing}
%
The conventional text preprocessing apart from the rest should include such steps as stop-word filtering and stemming~\cite{feldman}. In this work it was observed that performing of any of those procedures dramatically decreases the system's performance, especially both in terms of the number of relations extracted and in their correspondence to the original ones in the text. Therefore, those steps were not performed to obtain the final results.

In the present work preprocessing stage mainly was limited to the proper named entity (NE) extraction from the text and co-reference and anaphora resolutions. Entities of types \textit{Person}, \textit{Organization} and \textit{Location} were extracted from the articles. Later they were normalized to the same format and together they formed a set of NE dictionaries, which were essential at the mining stage. 

Co-reference resolution was crucial in this work due to the fact that the articles from the news agencies are composed in a formal language and consist of numerous references to the objects mentioned. The two main tools that were tried for the reference handling were BART~\cite{bart} and  Stanford-NLP~\cite{stanford}. The latter was finally used because of the information structure it provides - very similar to the one of dependency grammars. This structure possesses a vast field for further improvement of the relation extraction models used in the text mining phase. In this work the references found were replaced with the phrase which they were referring to. The replacement was done with a custom Perl script.
%
\section{Text Mining}
%
After all the preprocessing is done, relation extraction techniques can be applied to the document corpus, that have been cleaned-up in the preprocessing phase. In this work ReVerb~\cite{reverb} was used as a relation extraction tool. It takes as an input all the preprocessed text files and outputs sentences in the form \{\textit{Part 1}\}--\{\textit{Relation}\}--\{\textit{Part 2}\} where the \textit{Relation} is a verb phrase (VP), as it follows from the tool name, and \textit{Parts 1} and \textit{2} are noun phrases (NP). 

The verb extracted from the tool is given in its gerund form, meaning that for every sentence where the verb (e.g. ``attack") represents all its inflected forms (e.g. ``attacked", ``attacking", "has attacked" etc.). This is an advantage of the tool since this leads to very compressed verb representation while having none of the discussed disadvantages of other data reduction procedures, such as stemming. Furthermore, ReVerb outputs a confidence parameter along with each extracted relation which defines the probability of a correct extraction. Since there was a need for ``definite" relations in this work, this parameter was set to 0.8 filtering out the relations with smaller confidence values. 

Once all the relations were extracted from the corpus, the next step was to filter them keeping only the relations between entities that exist in the dictionary that was created in the preprocessing phase. Since in this work only inter-entity relations were needed, only sentences that had entities on both parts were considered as valid. 

Finally, the relations were normalized over the entities which they represented meaning that all the sentences of the form \{\textit{NP}\}--\{\textit{VP}\}--\{\textit{NP}\} where reduced to the form \{\textit{Entity 1}\}--\{\textit{VP}\}--\{\textit{Entity 2}\}. This was necessary to reduce and where possible prevent the duplication of the entities (e.g. \textit{NP}\{Vladimir Putin's address\}$\Rightarrow$\textit{Entity}\{Vladimir Putin\}). The extraction of the relations from the results, as well as the normalization and string manipulation so that the output is a valid format that can be passed to Gephi~\cite{gephi} for visualization were done using custom Perl scripts.
%
\subsection{The application}
%
For the ease of usage, maintainability and enhancement of the text processing methods described, a desktop application was implemented. Qt was used as a development platform, in order to keep the application cross-platform. Its main window' interface is shown in Fig.~\ref{Application}.
\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.8\textwidth]{images/Application}
    \caption{The application's main interface}
  \label{Application}
\end{figure}

The processing done by the application is fully automated and requires the user only to supply the input text files with the articles s/he wants to analyze. Then the processing is already structured in an optimal way, which eliminates the need to figure out what should be run and when. As such, in Fig.~\ref{Application} NE extraction, which is placed in the preprocessing section of the present work, is performed only when required, namely at step 4. This allows to largely decrease the dictionaries size by the extracting of only the entities present in the relations found with the set confidence threshold. The decrease of the dictionaries size in turn largely increases the processing efficiency and improves the precision of the relation extraction.

Note that the application requires the user to have Java, Perl and KNIME installed on the workstation, and the used machine must have at least 2Gb of RAM allocated fro the application to run. The paths to the binary files of those have to be specified in a ``Settings" window. In addition, relations may be extracted based on the mentioned confidence value, which is user-defined and may vary from 0 to 100\%.

Unfortunately, the progress bar was not integrated in the application to inform the user of the time left to wait. This is due to the time constraints. Also, the proper documentation is yet missing. Finally, currently the application is hardly customizable from the outside, therefore more settings should be added.
%
\section{Visualization}
%
Several modern tools were explored for the task of visualization. Among those, most notable are - GATE~\cite{gate}, KNIME and Gephi. At first, on the stage of the co-reference resolution, it was thought that GATE as a tool specifically designed for visual depiction of the text analysis results would suit best. However, it turned out that in terms of the visualization of the whole corpus processing results it is a very inflexible tool, which does not allow any user interaction with the visualization. It was decided, that GATE works best for the single document processing analysis in the situations when new or modified text mining algorithms are tested, but it does not fit the needs of a large scale mining.

After that, KNIME was used for basic visualizations almost on every processing stage. This tool is very helpful for the data input-output control purposes. Apart from that, KNIME was used for the most frequent keywords extraction and visualization in the form of an intuitive tag cloud (see Fig.~\ref{Cloud}) and for the keyword clustering and visualization, both k-means and hierarchical.

The most efficient and meaningful visualizations of the extracted relations were produced by Gephi. Several types of representations were tried in it. It can be noticed that each representation tried suits well for the specific tasks. For example, relation types shown as nodes as well works good when the intention is to show the relation-centered graph (see Fig.~\ref{AllRelations}), which is useful when specific relations are of the major interest (e.g. ``killed", ``accused" (see Fig.~\ref{Accusations}), etc.). On the other hand, in more general settings, when the task is more about the identification of what connects the entities together, a visualization where relations are just shown as edge labels works best (see Fig.~\ref{KievNetwork}).
% 
\section{Discussion and Limitations}
%
Some of the relations that occur only once in the whole corpus are treated as noise and filtered out, under the assumption that they might be generally irrelevant to the topic, or be very minor issues which are not of large significance. This leaves only the most occurring relations and consequently the objective ones in the end.

It must be also noted that numeric facts (e.g. the number of casualties) referring to a certain event and their temporal fluctuations, cannot be effectively extracted within the described framework. This is due to the fact that many different events happen simultaneously and, since the data comes from many different agencies, there is enough noise to make extracting such events unfeasible.

Finally, some improvements that could raise the quality of the framework are the following. Firstly, in the co-reference resolution and relation extraction phases, negation handling  should improve the quality of the relations that are extracted. Furthermore, the algorithm of extracting entities from the relations can be improved; A NP may contain more than one entity simultaneously, but only the first one matched with any of the dictionary entities is selected as a replacement. Thus a matching strategy that takes into account all the entities that appear in a NP could be implemented. This could create more combinations of relations, but it's not clear if it will improve the end result since it could introduce processing noise to the extraction results. Lastly, improving the interface that is provided with highly customizable parameters will make the application more flexible and less domain dependent.
%
\section{Conclusion}
%
Extracting the objective facts regarding the same events covered by different sources is not a trivial task. In this work, a framework that can accurately extract relations from a corpus of non-homogeneous opinionated text documents was proposed. Some visualization examples of the processing results are shown to demonstrate the versatility of the framework. Furthermore, an application that makes the procedure of relation extraction easier for the user was presented. Finally, major limitations of the framework were addressed along with the ideas of future work that will improve the results' quality of the described relation extraction techniques.
%
% ---- Bibliography ----
%
\begin{thebibliography}{99}
%

\bibitem{gephi}
Bastian M, Heymann S, Jacomy M (2009)
Gephi: an open source software for exploring and manipulating networks.
ICWSM 361--362

\bibitem{knime}
Berthold MR, Cebron N, Dill F, Gabriel TR, KÃ¶tter T, Meinl T, Wiswedel B (2008)
KNIME: The Konstanz information miner.
Springer Berlin Heidelberg 319--326

\bibitem{gate}
Cunningham H, Maynard D, Bontcheva K (2011)
Text processing with gate.
Gateway Press CA.

\bibitem {stanford}
De Marneffe MC, Manning CD (2008)
Stanford typed dependencies manual. \texttt{http://nlp.stanford.edu/software/dependencies\_manual.pdf}

\bibitem {reverb}
Fader A, Soderland S, Etzioni O (2011) 
Identifying relations for open information extraction. 
Proc. Conf. Empirical Methods in Nat. Lang. Proc. 1535--1545
Association for Computational Linguistics.

\bibitem{feldman}
Feldman R, Sanger J (2007) 
The text mining handbook.
Cambridge University Press.

\bibitem {perl}
Holzner S (1999)
Perl core language little black book. 
Coriolis Group Books

\bibitem{bart}
Versley Y, Ponzetto SP, Poesio M, Eidelman V, Jern A, Smith J, Moschitti A (2008)
BART: A modular toolkit for coreference resolution.
Proc. 46th Annual Meeting of the Assoc Comp Ling on Human Lang Tech 9--12

\end{thebibliography}

\clearpage
\appendix
\appendixpage

\renewcommand\thefigure{\thesection.\arabic{figure}} 

%
\section{Visualization examples}
%
\setcounter{figure}{0}

\begin{figure}[htbp]
  \centering
     \makebox[\textwidth][c]{\includegraphics[width=1\textwidth]{images/Cloud}}
    \caption{The most frequent stemmed keywords of the used corpus}
  \label{Cloud}
\end{figure}
\begin{figure}[htbp]
  \centering
     \makebox[\textwidth][c]{\includegraphics[width=18cm]{images/AllRelations}}
    \captionsetup{justification=centering}
    \caption{The most significant relations of the used corpus shown \\ as separate nodes (size - Betweenness Centrality, color - Modularity Class)}
  \label{AllRelations}
\end{figure}
\begin{figure}[htbp]
  \centering
     \makebox[\textwidth][c]{\includegraphics[width=18cm]{images/Accusations}}
    \captionsetup{justification=centering}
    \caption{The network of ``accuse" relations \\ (size - Eccentricity, color - Inbound Weight)}
  \label{Accusations}
\end{figure}
\begin{figure}[htbp]
  \centering
  \makebox[\textwidth][c]{\includegraphics[width=18cm]{images/KievNetwork}}%
    \captionsetup{justification=centering}
    \caption{Relational network of the entity ``Kiev", relations shown as labels (size - Eigenvector Centrality, color - Modularity Class)}
  \label{KievNetwork}
\end{figure}

\end{document}
